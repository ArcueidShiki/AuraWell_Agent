# RAG模块升级
## 升级内容
1. 用户检索升级，支持中英混合查询
2. 用户检索升级，使得无论是中文查询还是英文查询都能获得来自中英文双语的专业文献的支持
## 技术描述
额外引入以下库
* PyTorch CPU: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
* 推荐引用的轻量级翻译模型：MarianMT
### 中英文混合查询具体实现
方法名称：query_translation
1. 加载一个轻量级本地翻译模型负责翻译用户的查询请求, 该模型兼容PyTorch框架, 可以使用CPU进行推理
2. 使用langdetect库检测原查询语句的语言种类，如果是中文则执行中译英，如果是英文则执行英译中，两个版本的查询语句均应当保留
3. 将英文版本和中文版本的语言存放进一个Python字典类，并作为返回值
### 双语种专业文献支持
方法名称：retrieve_topK <br>
*提示：你不被建议修改这个方法的主要逻辑，请在原有逻辑的基础上进行扩展*
建议使用query_translation完成这项任务
1. 无论用户的原文本是什么语言, 都会被翻译成英文和中文两个版本
2. 将双语版本经由词嵌入模型向量化，然后分别使用两个语种版本的向量进行检索，每一次检索(k/2)个相关字段，向上取整
3. 将两个语种版本的检索结果合并至一个Python列表中，列表的每一个元素都是一个字符串，并作为最终的函数返回值。使用"cn"键存放中文内容，使用"en"键存放英文内容。
## 验收标准
1. 轻量级模型可以正确被加载并使用。
2. 无论是英文输入还是中文输入都可以被正确地转换为另一种语言。
3. 遭遇非法输入时，程序可以正确在终端输出警告，终止翻译，并将错误记录于日志中，但是不应当导致程序整体崩溃。
4. 获得正确输入时，字典中至少应当包含"cn"和"en"两个键，分别对应中文和英文输入。
5. RAG检索的结果至少应当包含总计k个相关字段
# 多模型梯度建设
## 升级内容
1. 用户问答体验升级, 优先使用deepseek-r1-0528模型, 但在此模型不可用或者回答延迟过长时，转而使用qwen-turbo进行回答
## 技术描述
在转换使用的模型时，不更改调用API的节点
### 模型降级的具体实现
1. 维护一个字典, 代表模型级别和模型名称之间的关系, HighPrecision对应deepseek-r1-0528, FastResponse对应qwen-turbo
2. 每一次问答记录从接收到用户问询到接收到大语言模型的回复花费的时间，如果HighPrecision级别对应的模型花费时间过长(3分钟以上)，则降级为FastResponse对应的模型进行回答
3. 请注意，转换模型时仍然需要保持上下文，至少保留上一次问答的背景
## 验收标准
1. deepseek-r1-0528和qwen-turbo两个模型均可以正确被调用
2. 先进行一次deepseek-r1-0528的回答，下一次问答转而使用qwen-turbo，如果qwen-turbo可以输出正确的内容，则算测试通过
